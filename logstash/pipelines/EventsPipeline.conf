input { pipeline { address => "Events" } }

filter {
  # Use the given timestamp from the event for the logstash timestamp and send to ElasticSearch
  date {
      match => [ "time", "UNIX_MS" ]
  }
  if [type] != "system" {
    drop { }
  }
  mutate {
    add_field => { "[processInfo][gatewayName]" => "%{[gatewayName]}" }
    add_field => { "[processInfo][gatewayRegion]" => "%{[gatewayRegion]}" }
    remove_field => [ "agent", "log", "logtype", "tags", "type", "ecs", "time", "gatewayRegion", "gatewayName", "host" ]
  }
}

output {
  if [correlationId] {
    elasticsearch {
      hosts => "${ELASTICSEARCH_HOST}"
      index => "apigw-traffic-details-%{+YYYY.MM.dd}"
      template => "${HOME}/index_templates/traffic_details_index_template.json"
      template_name => "traffic-details"
      template_overwrite => true
      document_id => "%{correlationId}"
      action => "update"
      doc_as_upsert => true
      id => "TrafficEventInformation" # Not used today - For instance to support custom properties
    }
  } else {
    elasticsearch {
      hosts => "${ELASTICSEARCH_HOST}"
      index => "apigw-monitoring-%{+YYYY.MM}"
      template => "${HOME}/index_templates/monitoring_event_index_template.json"
      template_name => "apigw-monitoring"
      template_overwrite => true
      id => "MonitoringInformation"
    }
  }
# Enable if you would like to see outgoing event messages
#  stdout {
#    codec => rubydebug
#  }
}